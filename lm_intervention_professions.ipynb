{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/boknilev/lm-intervention/blob/master/lm_intervention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mpVWB0MeXxbT",
    "outputId": "b0737332-f626-47f8-be32-09033770258c"
   },
   "outputs": [],
   "source": [
    "#!pip install pytorch-transformers\n",
    "#!pip install spacy ftfy==4.4.3\n",
    "#!python -m spacy download en\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from pytorch_transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import Intervention, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = Model(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcrFo1lMfpci"
   },
   "outputs": [],
   "source": [
    "# Currently not implemented/needed functions. \n",
    "def plot_log_probs(layer_to_candidate1_log_probs, layer_to_candidate2_log_probs):\n",
    "    \n",
    "    raise NotImplementedError\n",
    "        \n",
    "def print_neuron_hook(module, input, output, position, neuron):\n",
    "        #print(output.shape) \n",
    "        print(output[0][position][neuron])\n",
    "        \n",
    "def print_all_hook(module, input, output, position):\n",
    "    #print(output.shape) \n",
    "    print(output[0][position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bookkeeping for all the experiments\n",
    "\n",
    "ToDo: actually run all of them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: does not include teacher\n",
    "interventions = {}\n",
    "with open('professions_neutral.json', 'r') as f:\n",
    "    for l in f: \n",
    "        # there is only one line that eval's to an array\n",
    "        for j in eval(l):\n",
    "            biased_word = j[0]\n",
    "            interventions[biased_word] = Intervention(\n",
    "                    tokenizer,\n",
    "                    \"The {} said that\",\n",
    "                    [biased_word, \"man\", \"woman\"],\n",
    "                    [\"he\", \"she\"],\n",
    "                    device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Need to double check that the sentences all make sense\n",
    "male_interventions = []\n",
    "with open('male_word_said.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        # Strip off the \\n\n",
    "        biased_word = l[:-1]\n",
    "        male_interventions.append(\n",
    "                Intervention(\n",
    "                    tokenizer,\n",
    "                    \"The {} said that\",\n",
    "                    [biased_word, \"man\", \"woman\"],\n",
    "                    [\"he\", \"she\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Need to double check that the sentences all make sense\n",
    "female_interventions = []\n",
    "with open('female_word_said.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        # Strip off the \\n\n",
    "        biased_word = l[:-1]\n",
    "        female_interventions.append(\n",
    "                Intervention(\n",
    "                    tokenizer,\n",
    "                    \"The {} said that\",\n",
    "                    [biased_word, \"man\", \"woman\"],\n",
    "                    [\"he\", \"she\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Professions Experiment Run\n",
    "\n",
    "ToDo: add eval/vis of result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aE8stKqggffZ",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1aa201f41f4719934e43700eaaa2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='professions', max=292, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base case: The accountant said that ____\n",
      "Ġhe: 1.48%\n",
      "Ġshe: 0.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 1/12 [00:16<03:01, 16.48s/it]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:32<02:43, 16.38s/it]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:48<02:26, 16.27s/it]\u001b[A\n",
      " 33%|███▎      | 4/12 [01:04<02:09, 16.20s/it]\u001b[A\n",
      " 42%|████▏     | 5/12 [01:20<01:53, 16.15s/it]\u001b[A\n",
      " 50%|█████     | 6/12 [01:36<01:36, 16.14s/it]\u001b[A\n",
      " 58%|█████▊    | 7/12 [01:53<01:20, 16.18s/it]\u001b[A\n",
      " 67%|██████▋   | 8/12 [02:09<01:04, 16.21s/it]\u001b[A\n",
      " 75%|███████▌  | 9/12 [02:25<00:48, 16.21s/it]\u001b[A\n",
      " 83%|████████▎ | 10/12 [02:41<00:32, 16.19s/it]\u001b[A\n",
      " 92%|█████████▏| 11/12 [02:57<00:16, 16.19s/it]\u001b[A\n",
      "100%|██████████| 12/12 [03:14<00:00, 16.18s/it]\u001b[A\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base case: The acquaintance said that ____\n",
      "Ġhe: 1.11%\n",
      "Ġshe: 0.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 1/12 [00:16<02:59, 16.34s/it]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:32<02:43, 16.34s/it]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:48<02:26, 16.33s/it]\u001b[A\n",
      " 33%|███▎      | 4/12 [01:05<02:10, 16.32s/it]\u001b[A\n",
      " 42%|████▏     | 5/12 [01:21<01:54, 16.31s/it]\u001b[A\n",
      " 50%|█████     | 6/12 [01:38<01:38, 16.40s/it]\u001b[A\n",
      " 58%|█████▊    | 7/12 [01:54<01:21, 16.37s/it]\u001b[A\n",
      " 67%|██████▋   | 8/12 [02:10<01:05, 16.40s/it]\u001b[A\n",
      " 75%|███████▌  | 9/12 [02:27<00:49, 16.42s/it]\u001b[A\n",
      " 83%|████████▎ | 10/12 [02:43<00:32, 16.41s/it]\u001b[A\n",
      " 92%|█████████▏| 11/12 [03:00<00:16, 16.43s/it]\u001b[A\n",
      "100%|██████████| 12/12 [03:16<00:00, 16.41s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "intervention_results = model.neuron_intervention_experiment(interventions)\n",
    "\n",
    "# TODO: we need to look at the log prob distribution over the candidates and how that changes by intervention  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>base_string</th>\n",
       "      <th>first_condition</th>\n",
       "      <th>second_condition</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>layer</th>\n",
       "      <th>neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accountant</td>\n",
       "      <td>The accountant said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>Ġshe</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>3.515864e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accountant</td>\n",
       "      <td>The accountant said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>Ġshe</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>3.351511e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accountant</td>\n",
       "      <td>The accountant said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>Ġshe</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>8.255077e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accountant</td>\n",
       "      <td>The accountant said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>Ġshe</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>1.152566e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accountant</td>\n",
       "      <td>The accountant said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>Ġshe</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>1.315481e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word               base_string first_condition second_condition  \\\n",
       "0  accountant  The accountant said that             Ġhe             Ġshe   \n",
       "1  accountant  The accountant said that             Ġhe             Ġshe   \n",
       "2  accountant  The accountant said that             Ġhe             Ġshe   \n",
       "3  accountant  The accountant said that             Ġhe             Ġshe   \n",
       "4  accountant  The accountant said that             Ġhe             Ġshe   \n",
       "\n",
       "         p1            p2  layer  neuron  \n",
       "0  0.004588  3.515864e-04      0       0  \n",
       "1  0.001269  3.351511e-07      0       1  \n",
       "2  0.006750  8.255077e-04      0       2  \n",
       "3  0.009896  1.152566e-03      0       3  \n",
       "4  0.012687  1.315481e-03      0       4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_results_to_pd(interventions, intervention_results):    \n",
    "    results = []\n",
    "    for word in intervention_results:\n",
    "        intervention = interventions[word]\n",
    "        _, c1_probs, _, c2_probs = intervention_results[word] \n",
    "        for c1_neurons, c2_neurons in zip(c1_probs.items(), c2_probs.items()):\n",
    "            cur_layer = c1_neurons[0]\n",
    "            first_probs = c1_neurons[1]\n",
    "            second_probs = c2_neurons[1]\n",
    "            for ix, (p1, p2) in enumerate(zip(first_probs, second_probs)):\n",
    "                results.append({\n",
    "                     'word': word,\n",
    "                     'base_string': intervention.base_strings[0],\n",
    "                     'first_condition': intervention.candidates[0],\n",
    "                     'second_condition': intervention.candidates[1],\n",
    "                     'p1': float(p1),\n",
    "                     'p2': float(p2),\n",
    "                     'layer': cur_layer,\n",
    "                     'neuron': ix})\n",
    "    return pd.DataFrame(results)\n",
    "df = convert_results_to_pd(interventions, intervention_results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Report aggregate\n",
    "'''\n",
    "#print('more probable candidate per layer, across all neurons in the layer')\n",
    "#print('candidate1:', intervention.candidates[0], c1)\n",
    "#print('candidate2:', intervention.candidates[1], c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "lm-intervention.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
