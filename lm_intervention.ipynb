{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/boknilev/lm-intervention/blob/master/lm_intervention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mpVWB0MeXxbT",
    "outputId": "b0737332-f626-47f8-be32-09033770258c"
   },
   "outputs": [],
   "source": [
    "#!pip install pytorch-transformers\n",
    "#!pip install spacy ftfy==4.4.3\n",
    "#!python -m spacy download en\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "from pytorch_transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import Intervention, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcrFo1lMfpci"
   },
   "outputs": [],
   "source": [
    "# Currently not implemented/needed functions. \n",
    "def plot_log_probs(layer_to_candidate1_log_probs, layer_to_candidate2_log_probs):\n",
    "    \n",
    "    raise NotImplementedError\n",
    "        \n",
    "def print_neuron_hook(module, input, output, position, neuron):\n",
    "        #print(output.shape) \n",
    "        print(output[0][position][neuron])\n",
    "        \n",
    "def print_all_hook(module, input, output, position):\n",
    "    #print(output.shape) \n",
    "    print(output[0][position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bookkeeping for all the experiments\n",
    "\n",
    "ToDo: actually run all of them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test experiment\n",
    "'''\n",
    "base_sentence = \"The {} said that\"\n",
    "biased_word = \"teacher\"\n",
    "intervention = Intervention(\n",
    "        tokenizer,\n",
    "        base_sentence,\n",
    "        [biased_word, \"man\", \"woman\"],\n",
    "        [\"he\", \"she\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential other sentences we could check. They could amplify the effect\n",
    "# To Do: make different interventions with each after finalizing list.\n",
    "base_sentence = \"The {} said that\"\n",
    "base_sentence = \"The {} yelled that\"\n",
    "base_sentence = \"The {} whispered that\"\n",
    "base_sentence = \"The {} wanted that\"\n",
    "base_sentence = \"The {} desired that\"\n",
    "base_sentence = \"The {} wished that\"\n",
    "\n",
    "base_sentence = \"A {} caught the ball.\"\n",
    "base_sentence = \"A {} cooked the dinner.\"\n",
    "base_sentence = \"The {} baked the cake.\"\n",
    "base_sentence = \"A {} raised the gun.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: does not include teacher\n",
    "profession_interventions = []\n",
    "with open('professions.json', 'r') as f:\n",
    "    for l in f: \n",
    "        # there is only one line that eval's to an array\n",
    "        for j in eval(l):\n",
    "            biased_word = j[0]\n",
    "            profession_interventions.append(\n",
    "                Intervention(\n",
    "                    tokenizer,\n",
    "                    \"The {} said that\",\n",
    "                    [biased_word, \"man\", \"woman\"],\n",
    "                    [\"he\", \"she\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Need to double check that the sentences all make sense\n",
    "male_interventions = []\n",
    "with open('male_word.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        # Strip off the \\n\n",
    "        biased_word = l[:-1]\n",
    "        male_interventions.append(\n",
    "                Intervention(\n",
    "                    tokenizer,\n",
    "                    \"The {} said that\",\n",
    "                    [biased_word, \"man\", \"woman\"],\n",
    "                    [\"he\", \"she\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Need to double check that the sentences all make sense\n",
    "female_interventions = []\n",
    "with open('female_word.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        # Strip off the \\n\n",
    "        biased_word = l[:-1]\n",
    "        female_interventions.append(\n",
    "                Intervention(\n",
    "                    tokenizer,\n",
    "                    \"The {} said that\",\n",
    "                    [biased_word, \"man\", \"woman\"],\n",
    "                    [\"he\", \"she\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Test Experiment Run\n",
    "\n",
    "ToDo: add eval/vis of result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aE8stKqggffZ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base case: The teacher said that ____\n",
      "Ġhe: 9.81%\n",
      "Ġshe: 12.17%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" Code draws on https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_gpt2.py \"\"\"        \n",
    "c1, c1_probs, c2, c2_probs = model.neuron_intervention_experiment(intervention)\n",
    "# TODO: we need to look at the log prob distribution over the candidates and how that changes by intervention  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_string</th>\n",
       "      <th>first_condition</th>\n",
       "      <th>layer</th>\n",
       "      <th>neuron</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>second_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The teacher said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036626</td>\n",
       "      <td>0.014896</td>\n",
       "      <td>Ġshe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The teacher said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035115</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>Ġshe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The teacher said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.078671</td>\n",
       "      <td>0.021347</td>\n",
       "      <td>Ġshe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The teacher said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.036290</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>Ġshe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The teacher said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.101923</td>\n",
       "      <td>0.072069</td>\n",
       "      <td>Ġshe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             base_string first_condition  layer  neuron        p1        p2  \\\n",
       "0  The teacher said that             Ġhe      0       0  0.036626  0.014896   \n",
       "1  The teacher said that             Ġhe      0       1  0.035115  0.001850   \n",
       "2  The teacher said that             Ġhe      0       2  0.078671  0.021347   \n",
       "3  The teacher said that             Ġhe      0       3  0.036290  0.020767   \n",
       "4  The teacher said that             Ġhe      0       4  0.101923  0.072069   \n",
       "\n",
       "  second_condition  \n",
       "0             Ġshe  \n",
       "1             Ġshe  \n",
       "2             Ġshe  \n",
       "3             Ġshe  \n",
       "4             Ġshe  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_result_to_pd(intervention, c1_probs, c2_probs):\n",
    "    results = []\n",
    "    for c1_neurons, c2_neurons in zip(c1_probs.items(), c2_probs.items()):\n",
    "        cur_layer = c1_neurons[0]\n",
    "        first_probs = c1_neurons[1]\n",
    "        second_probs = c2_neurons[1]\n",
    "        for ix, (p1, p2) in enumerate(zip(first_probs, second_probs)):\n",
    "            results.append({\n",
    "                 'base_string': intervention.base_strings[0],\n",
    "                 'first_condition': intervention.candidates[0],\n",
    "                 'second_condition': intervention.candidates[1],\n",
    "                 'p1': float(p1),\n",
    "                 'p2': float(p2),\n",
    "                 'layer': cur_layer,\n",
    "                 'neuron': ix})\n",
    "    return pd.DataFrame(results)\n",
    "df = convert_result_to_pd(intervention, c1_probs, c2_probs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more probable candidate per layer, across all neurons in the layer\n",
      "candidate1: Ġhe Counter({0: 672})\n",
      "candidate2: Ġshe Counter({0: 96})\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Report aggregate\n",
    "'''\n",
    "print('more probable candidate per layer, across all neurons in the layer')\n",
    "print('candidate1:', intervention.candidates[0], c1)\n",
    "print('candidate2:', intervention.candidates[1], c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "lm-intervention.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
