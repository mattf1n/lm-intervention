{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/boknilev/lm-intervention/blob/master/lm_intervention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mpVWB0MeXxbT",
    "outputId": "b0737332-f626-47f8-be32-09033770258c"
   },
   "outputs": [],
   "source": [
    "#!pip install pytorch-transformers\n",
    "#!pip install spacy ftfy==4.4.3\n",
    "#!python -m spacy download en\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "from pytorch_transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import Intervention, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = Model(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcrFo1lMfpci"
   },
   "outputs": [],
   "source": [
    "# Currently not implemented/needed functions. \n",
    "def plot_log_probs(layer_to_candidate1_log_probs, layer_to_candidate2_log_probs):\n",
    "    \n",
    "    raise NotImplementedError\n",
    "        \n",
    "def print_neuron_hook(module, input, output, position, neuron):\n",
    "        #print(output.shape) \n",
    "        print(output[0][position][neuron])\n",
    "        \n",
    "def print_all_hook(module, input, output, position):\n",
    "    #print(output.shape) \n",
    "    print(output[0][position])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bookkeeping for all the experiments\n",
    "\n",
    "ToDo: actually run all of them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test experiment\n",
    "'''\n",
    "base_sentence = \"The {} said that\"\n",
    "biased_word = \"teacher\"\n",
    "intervention = Intervention(\n",
    "        tokenizer,\n",
    "        base_sentence,\n",
    "        [biased_word, \"man\", \"woman\"],\n",
    "        [\"he\", \"she\"],\n",
    "        device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential other sentences we could check. They could amplify the effect\n",
    "# To Do: make different interventions with each after finalizing list.\n",
    "base_sentence = \"The {} said that\"\n",
    "base_sentence = \"The {} yelled that\"\n",
    "base_sentence = \"The {} whispered that\"\n",
    "base_sentence = \"The {} wanted that\"\n",
    "base_sentence = \"The {} desired that\"\n",
    "base_sentence = \"The {} wished that\"\n",
    "\n",
    "base_sentence = \"A {} caught the ball.\"\n",
    "base_sentence = \"A {} cooked the dinner.\"\n",
    "base_sentence = \"The {} baked the cake.\"\n",
    "base_sentence = \"A {} raised the gun.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: does not include teacher\n",
    "profession_interventions = []\n",
    "with open('professions.json', 'r') as f:\n",
    "    for l in f: \n",
    "        # there is only one line that eval's to an array\n",
    "        for j in eval(l):\n",
    "            biased_word = j[0]\n",
    "            profession_interventions.append(\n",
    "                Intervention(\n",
    "                    tokenizer,\n",
    "                    \"The {} said that\",\n",
    "                    [biased_word, \"man\", \"woman\"],\n",
    "                    [\"he\", \"she\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Need to double check that the sentences all make sense\n",
    "male_interventions = []\n",
    "with open('male_word.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        # Strip off the \\n\n",
    "        biased_word = l[:-1]\n",
    "        male_interventions.append(\n",
    "                Intervention(\n",
    "                    tokenizer,\n",
    "                    \"The {} said that\",\n",
    "                    [biased_word, \"man\", \"woman\"],\n",
    "                    [\"he\", \"she\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Need to double check that the sentences all make sense\n",
    "female_interventions = []\n",
    "with open('female_word.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        # Strip off the \\n\n",
    "        biased_word = l[:-1]\n",
    "        female_interventions.append(\n",
    "                Intervention(\n",
    "                    tokenizer,\n",
    "                    \"The {} said that\",\n",
    "                    [biased_word, \"man\", \"woman\"],\n",
    "                    [\"he\", \"she\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Test Experiment Run\n",
    "\n",
    "ToDo: add eval/vis of result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aE8stKqggffZ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base case: The teacher said that ____\n",
      "Ġhe: 9.81%\n",
      "Ġshe: 12.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 1/12 [00:07<01:21,  7.44s/it]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:14<01:14,  7.46s/it]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:22<01:07,  7.45s/it]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:29<00:59,  7.44s/it]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:37<00:52,  7.44s/it]\u001b[A\n",
      " 50%|█████     | 6/12 [00:44<00:44,  7.43s/it]\u001b[A\n",
      " 58%|█████▊    | 7/12 [00:52<00:37,  7.43s/it]\u001b[A\n",
      " 67%|██████▋   | 8/12 [00:59<00:29,  7.43s/it]\u001b[A\n",
      " 75%|███████▌  | 9/12 [01:06<00:22,  7.43s/it]\u001b[A\n",
      " 83%|████████▎ | 10/12 [01:14<00:14,  7.42s/it]\u001b[A\n",
      " 92%|█████████▏| 11/12 [01:21<00:07,  7.42s/it]\u001b[A\n",
      "100%|██████████| 12/12 [01:29<00:00,  7.45s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" Code draws on https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_gpt2.py \"\"\"        \n",
    "c1, c1_probs, c2, c2_probs = model.neuron_intervention_single_experiment(intervention)\n",
    "# TODO: we need to look at the log prob distribution over the candidates and how that changes by intervention  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_string</th>\n",
       "      <th>first_condition</th>\n",
       "      <th>second_condition</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>layer</th>\n",
       "      <th>neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The teacher said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>Ġshe</td>\n",
       "      <td>0.036626</td>\n",
       "      <td>0.014896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The teacher said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>Ġshe</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The teacher said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>Ġshe</td>\n",
       "      <td>0.078670</td>\n",
       "      <td>0.021347</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The teacher said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>Ġshe</td>\n",
       "      <td>0.036290</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The teacher said that</td>\n",
       "      <td>Ġhe</td>\n",
       "      <td>Ġshe</td>\n",
       "      <td>0.101922</td>\n",
       "      <td>0.072067</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             base_string first_condition second_condition        p1        p2  \\\n",
       "0  The teacher said that             Ġhe             Ġshe  0.036626  0.014896   \n",
       "1  The teacher said that             Ġhe             Ġshe  0.035116  0.001850   \n",
       "2  The teacher said that             Ġhe             Ġshe  0.078670  0.021347   \n",
       "3  The teacher said that             Ġhe             Ġshe  0.036290  0.020767   \n",
       "4  The teacher said that             Ġhe             Ġshe  0.101922  0.072067   \n",
       "\n",
       "   layer  neuron  \n",
       "0      0       0  \n",
       "1      0       1  \n",
       "2      0       2  \n",
       "3      0       3  \n",
       "4      0       4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_result_to_pd(intervention, c1_probs, c2_probs):\n",
    "    results = []\n",
    "    for c1_neurons, c2_neurons in zip(c1_probs.items(), c2_probs.items()):\n",
    "        cur_layer = c1_neurons[0]\n",
    "        first_probs = c1_neurons[1]\n",
    "        second_probs = c2_neurons[1]\n",
    "        for ix, (p1, p2) in enumerate(zip(first_probs, second_probs)):\n",
    "            results.append({\n",
    "                 'base_string': intervention.base_strings[0],\n",
    "                 'first_condition': intervention.candidates[0],\n",
    "                 'second_condition': intervention.candidates[1],\n",
    "                 'p1': float(p1),\n",
    "                 'p2': float(p2),\n",
    "                 'layer': cur_layer,\n",
    "                 'neuron': ix})\n",
    "    return pd.DataFrame(results)\n",
    "df = convert_result_to_pd(intervention, c1_probs, c2_probs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more probable candidate per layer, across all neurons in the layer\n",
      "candidate1: Ġhe Counter({0: 672, 2: 668, 1: 664, 3: 633, 4: 569, 5: 561, 6: 428, 7: 375, 8: 359, 9: 158, 10: 37})\n",
      "candidate2: Ġshe Counter({11: 768, 10: 731, 9: 610, 8: 409, 7: 393, 6: 340, 5: 207, 4: 199, 3: 135, 1: 104, 2: 100, 0: 96})\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Report aggregate\n",
    "'''\n",
    "print('more probable candidate per layer, across all neurons in the layer')\n",
    "print('candidate1:', intervention.candidates[0], c1)\n",
    "print('candidate2:', intervention.candidates[1], c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "lm-intervention.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
